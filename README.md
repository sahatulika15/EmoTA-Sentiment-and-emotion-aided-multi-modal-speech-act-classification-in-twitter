# Sentiment and Emotion aware Multi-modal Speech Act Classification in Twitter (Tweet Act Classification) : EmoTA

## This is the readme file that contains the information about the EmoTA dataset introduced in the following paper

**Paper Name:-** Towards Sentiment and Emotion aided Multi-modal Speech Act Classification in Twitter
>Speech Act Classification determining the communicative intent of an utterance has been investigated widely over the years as a standalone task. This holds true for discussion in any fora including social media platform such as Twitter. But the emotional state of the tweeter which has a considerable effect on the communication has not received the attention it deserves. Closely related to emotion is sentiment, and understanding of one helps understand the other. In this work, we firstly create a new multi-modal, emotion-TA (‘TA’means tweet act, ie, speech act in Twitter) dataset called EmoTA collected from open-source Twitter dataset. We propose a Dyadic Attention Mechanism (DAM) based multi-modal, adversarial multi-tasking framework. DAM incorporates intra-modal and inter-modal attention to fuse multiple modalities and learns generalized features across all the tasks. Experimental results indicate that the proposed framework boosts the performance of the primary task, ie, TA classification (TAC) by benefitting from the two secondary tasks, ie, Sentiment and Emotion Analysis compared to its uni-modal and single task TAC (tweet act classification) variants.

* **Authors:** Tulika Saha, Apoorva Upadhyaya, Sriparna Saha and Pushpak Bhattacharyya
* **Affiliation:** Indian Institute of Technology Patna, India
* **Corresponding Author:** [Tulika Saha] (sahatulika15@gmail.com)
* **Accepted(May, 2021):**  [Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)](https://aclanthology.org/2021.naacl-main.456/)
* **Accepted(June, 2021):**  [IEEE Transactions on Computational Social Systems (IEEE TCSS)](https://ieeexplore.ieee.org/abstract/document/9469005)

If you consider this dataset useful, please cite it as

```bash
@inproceedings{saha-etal-2021-towards,
    title = "Towards Sentiment and Emotion aided Multi-modal Speech Act Classification in {T}witter",
    author = "Saha, Tulika  and
      Upadhyaya, Apoorva  and
      Saha, Sriparna  and
      Bhattacharyya, Pushpak",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.456",
    doi = "10.18653/v1/2021.naacl-main.456",
    pages = "5727--5737",
}
```
OR
```bash
@ARTICLE{9469005,
  author={Saha, Tulika and Upadhyaya, Apoorva and Saha, Sriparna and Bhattacharyya, Pushpak},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={A Multitask Multimodal Ensemble Model for Sentiment- and Emotion-Aided Tweet Act Classification}, 
  year={2022},
  volume={9},
  number={2},
  pages={508-517},
  doi={10.1109/TCSS.2021.3088714}}
```


